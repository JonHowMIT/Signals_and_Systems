{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bdb7dd29-b00c-4a25-9fdd-0c6c82e2a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    import pyaudio\n",
    "except:\n",
    "    !pip3 install pyaudio\n",
    "    import pyaudio\n",
    "\n",
    "import wave\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import librosa, librosa.display\n",
    "except:\n",
    "    !pip3 install librosa\n",
    "    import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04d5c2af-4e77-4428-9790-4de914dff84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "#FORMAT = pyaudio.paFloat32\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 20\n",
    "WAVE_OUTPUT_FILENAME = \"recordedFile.wav\"\n",
    "device_index = 2\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "558a036b-6ff6-493f-a38b-686943378fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------record device list---------------------\n",
      "Input Device id  0  -  MacBook Pro Microphone\n",
      "Input Device id  2  -  Microsoft Teams Audio\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------record device list---------------------\")\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "\n",
    "print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adc429c8-d461-45ba-bc73-7957233e8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording via index 0\n"
     ]
    }
   ],
   "source": [
    "#index = int(input())\n",
    "index = 0\n",
    "print(\"recording via index \"+str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cc309-8073-4340-8c6d-2c84c93eeece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording started\n",
      "0.0 1.2 2.3 3.5 4.7 5.8 7.0 8.2 9.3 10.5 11.6 12.8 14.0 "
     ]
    }
   ],
   "source": [
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True, input_device_index = index,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording started\")\n",
    "Recordframes = []\n",
    "\n",
    "import struct\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK, exception_on_overflow = False)\n",
    "    Recordframes.append(data)\n",
    "    if (i%100 == 0):\n",
    "        print(f\"{time.time() - start:.1f} \",  end = '')\n",
    "tf = time.time() - start\n",
    "print (\"recording stopped\")\n",
    "\n",
    "signal = np.hstack(Recordframes)\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6c5fc-186f-4417-998a-f7c1ba45b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(Recordframes))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfcefd9-21e8-4252-9df7-88c109a72d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_f = np.frombuffer(signal, dtype='int16').astype('float32')\n",
    "plt.figure(figsize=(20, 5))\n",
    "t_ignore = 1\n",
    "librosa.display.waveshow(signal_f[t_ignore*RATE:], sr=RATE)\n",
    "plt.title('Waveplot', fontdict=dict(size=18))\n",
    "plt.xlabel('Time', fontdict=dict(size=18))\n",
    "plt.ylabel('Amplitude', fontdict=dict(size=18))\n",
    "plt.xlim(0,tf-t_ignore)\n",
    "plt.savefig('./data/mic_recorder_0.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45413813-f9da-4255-a6bc-eb99647c2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq, fftshift, ifft\n",
    "from scipy.signal import blackman\n",
    "\n",
    "y = signal_f[t_ignore*RATE:]\n",
    "y = y/max(y)\n",
    "N = len(y)\n",
    "fs = RATE\n",
    "T = N/fs\n",
    "t = np.arange(N)*T/N\n",
    "\n",
    "def nicegrid(ax=plt):\n",
    "    ax.grid(True, which='major', color='#666666', linestyle=':')\n",
    "    ax.grid(True, which='minor', color='#999999', linestyle=':', alpha=0.2)\n",
    "    ax.minorticks_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f143f7-bbd0-45f6-b748-f2c7332b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_fft = fft(y)\n",
    "f_bl = fftfreq(N, 1/fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c6f55-e83a-4589-a68f-547b55bc1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,4), dpi=150)\n",
    "fig.tight_layout(pad=2)\n",
    "ax1.plot(t, y.real, 'b:', t, y.imag, 'r:')\n",
    "ax1.set_ylabel('$y_{bl}[nT_s]$')\n",
    "ax1.set_xlabel('$t$')\n",
    "ax1.legend(['y(t).real','y(t).imag'])\n",
    "ax1.set_title('Snippet of data')\n",
    "nicegrid(ax1)\n",
    "\n",
    "ax2.plot(f_bl[0:N//2], np.abs(Y_fft[0:N//2]),'b-')\n",
    "ax2.set_ylabel('FFT $y_{bl}[nT_s]$')\n",
    "ax2.set_xlabel('$f$')\n",
    "ax2.set_xlim([0, fs/2])\n",
    "ax2.legend(['Y_{fft}(f)','Y_{given}(f)'])\n",
    "ax2.set_title('FFT of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fec37e-b60e-48c6-8ca0-987375088530",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_freq = fs/N\n",
    "\n",
    "# bounds of rect in Y(f)\n",
    "f_low = 2000\n",
    "f_high = 15000\n",
    "# find equivalent positions in Y(f) \n",
    "n_low = int(f_low/delta_freq)\n",
    "n_high = int(f_high/delta_freq)\n",
    "L1 = np.arange(n_low,n_high)\n",
    "\n",
    "Y_n = np.zeros((N,), dtype=complex)\n",
    "# create random phase needed for correct ifft process\n",
    "rng = np.random.default_rng()\n",
    "phi = rng.uniform(0, 2*np.pi, (len(L1),))\n",
    "\n",
    "# create Y(f)\n",
    "if (0):\n",
    "    mag_temp = np.sin(np.pi*np.arange(0,n_high-n_low)/(n_high-n_low))\n",
    "else:\n",
    "    mag_temp = 250*np.ones([1,n_high-n_low])\n",
    "    \n",
    "Y_n[L1] = mag_temp*np.exp(1j*phi)\n",
    "# add complex conjugate at upper end to ensure that y[n] real\n",
    "Y_n[N-L1] = np.conj(Y_n[L1])\n",
    "\n",
    "# create y[n]\n",
    "noise = ifft(Y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475b6e2-0011-48b9-940d-d8a705194824",
   "metadata": {},
   "outputs": [],
   "source": [
    "yn = y + noise.real\n",
    "Y_fft_n = fft(yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3f56d-dabc-4ae3-aa89-2a30212ee1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,4), dpi=150)\n",
    "fig.tight_layout(pad=2)\n",
    "ax1.plot(t, y, 'b:', t, yn, 'r:',alpha=0.2)\n",
    "ax1.set_ylabel('$y_{bl}[nT_s]$')\n",
    "ax1.set_xlabel('$t$')\n",
    "ax1.legend(['Signal','Noisy signal'])\n",
    "ax1.set_title('Snippet of data')\n",
    "nicegrid(ax1)\n",
    "\n",
    "ax2.plot(f_bl[0:N//2], np.abs(Y_fft[0:N//2]),'b-')\n",
    "ax2.plot(f_bl[0:N//2], np.abs(Y_fft_n[0:N//2]),'r:')\n",
    "ax2.set_ylabel('FFT $y_{bl}[nT_s]$')\n",
    "ax2.set_xlabel('$f$')\n",
    "ax2.set_xlim([0, fs/2])\n",
    "ax2.legend(['Signal','Noisy signal'])\n",
    "ax2.set_title('FFT of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5f327-40e7-4b38-8358-890c4d6c314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low Pass\n",
    "b_low, a_low = signal.butter(2, 3000, 'low', fs=fs)\n",
    "f_low, h_low = signal.freqz(b_low, a_low,fs=fs,worN=1000)\n",
    "yn_lp = signal.lfilter(b_low, a_low, yn)\n",
    "Yn_lp_fft = fft(yn_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d356dd9-f6d1-42b2-a0a4-b15e9aca4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,4), dpi=150)\n",
    "eps = 1e-12\n",
    "ax1.plot(f_low, 20 * np.log10(abs(h_low+eps)),'b-',label='LP')\n",
    "ax1.set_title('Butterworth filter frequency response')\n",
    "ax1.set_xlabel('Frequency [Hz]')\n",
    "ax1.set_ylabel('Amplitude [dB]')\n",
    "ax1.set_xlim([0, fs/4])\n",
    "ax1.set_ylim([-20, 5])\n",
    "nicegrid()\n",
    "\n",
    "ax2.plot(f_bl[0:N//2], np.abs(Yn_lp_fft[0:N//2]),'b-')\n",
    "ax2.plot(f_bl[0:N//2], np.abs(Y_fft_n[0:N//2]),'r--',alpha = 0.3)\n",
    "ax2.set_ylabel('FFT $y_{bl}[nT_s]$')\n",
    "ax2.set_xlabel('$f$')\n",
    "ax2.set_xlim([0, fs/4])\n",
    "ax2.legend(['FFT noisy signal','LP of noisy signal'])\n",
    "ax2.set_title('FFT of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8abbdf-2136-4d5e-bc9b-c2c07a47a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "y_norm = y/max(abs(y))\n",
    "write(\"data/example.wav\", RATE, y_norm.astype(np.float32))\n",
    "yn_norm = yn/max(abs(yn))\n",
    "write(\"data/example_noisy.wav\", RATE, yn_norm.astype(np.float32))\n",
    "yn_lp_norm = yn/max(abs(yn_lp))\n",
    "write(\"data/example_noisy_lp.wav\", RATE, yn_lp_norm.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b67b2-ae26-4a27-9027-51f63de8ef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bf9ea-d4cb-4a0d-ab9c-43bb1bba41f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
